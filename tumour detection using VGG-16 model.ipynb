{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjwlBzIKGa5_"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import os,sys\n",
    "import imutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from os import listdir\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38045,
     "status": "ok",
     "timestamp": 1588150016805,
     "user": {
      "displayName": "Sumant Balli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFcJbFXv0ZDWaYwSijqTaayN_oReKkcRMbR2h21w=s64",
      "userId": "08653643334008630126"
     },
     "user_tz": -330
    },
    "id": "VUpZ_PmoGiqS",
    "outputId": "c8b6023b-3c41-4544-c29a-301ebf413a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ajKSqXSGa6F"
   },
   "outputs": [],
   "source": [
    "def crop_brain_contour(image, plot=False):\n",
    "    \n",
    "    #import imutils\n",
    "    #import cv2\n",
    "    #from matplotlib import pyplot as plt\n",
    "    \n",
    "    # Convert the image to grayscale, and blur it slightly\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Threshold the image, then perform a series of erosions +\n",
    "    # dilations to remove any small regions of noise\n",
    "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # Find contours in thresholded image, then grab the largest one\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    \n",
    "\n",
    "    # Find the extreme points\n",
    "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "    \n",
    "    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n",
    "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            \n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        plt.tick_params(axis='both', which='both', \n",
    "                        top=False, bottom=False, left=False, right=False,\n",
    "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "        \n",
    "        plt.title('Original Image')\n",
    "            \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(new_image)\n",
    "\n",
    "        plt.tick_params(axis='both', which='both', \n",
    "                        top=False, bottom=False, left=False, right=False,\n",
    "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "\n",
    "        plt.title('Step 6:Cropped Image')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fX9k16dBGa6K"
   },
   "outputs": [],
   "source": [
    "def load_data(dir_list, image_size):\n",
    "    \"\"\"\n",
    "    Read images, resize and normalize them. \n",
    "    Arguments:\n",
    "        dir_list: list of strings representing file directories.\n",
    "    Returns:\n",
    "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
    "        y: A numpy array with shape = (#_examples, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    # load all images in a directory\n",
    "    X = []\n",
    "    y = []\n",
    "    image_width, image_height = image_size\n",
    "    \n",
    "    for directory in dir_list:\n",
    "        for filename in os.listdir(directory):\n",
    "            image = cv2.imread(os.path.join(directory,filename))\n",
    "            # load the image\n",
    "            # crop the brain and ignore the unnecessary rest part of the image\n",
    "            image = crop_brain_contour(image, plot=False)\n",
    "            # resize image\n",
    "            image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
    "            # normalize values\n",
    "            image = image / 255.\n",
    "            # convert image to numpy array and append it to X\n",
    "            X.append(image)\n",
    "            # append a value of 1 to the target array if the image\n",
    "            # is in the folder named 'yes', otherwise append 0.\n",
    "            if directory[-4:] == 'yes1':\n",
    "                y.append([1])\n",
    "            else:\n",
    "                y.append([0])\n",
    "                \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "      \n",
    "    # Shuffle the data\n",
    "    X, y = shuffle(X, y)\n",
    "    \n",
    "    print(f'Number of examples is: {len(X)}')\n",
    "    print(f'X shape is: {X.shape}')\n",
    "    print(f'y shape is: {y.shape}')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1308061,
     "status": "ok",
     "timestamp": 1588151436182,
     "user": {
      "displayName": "Sumant Balli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFcJbFXv0ZDWaYwSijqTaayN_oReKkcRMbR2h21w=s64",
      "userId": "08653643334008630126"
     },
     "user_tz": -330
    },
    "id": "nn5irZ9xGa6O",
    "outputId": "a5b1ebbd-bddf-472b-bc33-d807dd5881b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples is: 2065\n",
      "X shape is: (2065, 224, 224, 3)\n",
      "y shape is: (2065, 1)\n"
     ]
    }
   ],
   "source": [
    "augmented_yes = '/content/drive/My Drive/no1/no1' \n",
    "augmented_no = '/content/drive/My Drive/yes1'\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = (224, 224)\n",
    "\n",
    "X, y = load_data([augmented_yes, augmented_no], (IMG_WIDTH, IMG_HEIGHT)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b31cCm40Ga6U"
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2):\n",
    "       \n",
    "    \"\"\"\n",
    "    Splits data into training, development and test sets.\n",
    "    Arguments:\n",
    "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
    "        y: A numpy array with shape = (#_examples, 1)\n",
    "    Returns:\n",
    "        X_train: A numpy array with shape = (#_train_examples, image_width, image_height, #_channels)\n",
    "        y_train: A numpy array with shape = (#_train_examples, 1)\n",
    "        X_val: A numpy array with shape = (#_val_examples, image_width, image_height, #_channels)\n",
    "        y_val: A numpy array with shape = (#_val_examples, 1)\n",
    "        X_test: A numpy array with shape = (#_test_examples, image_width, image_height, #_channels)\n",
    "        y_test: A numpy array with shape = (#_test_examples, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=test_size)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xf3OQ2EjGa6X"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1661,
     "status": "ok",
     "timestamp": 1588151456036,
     "user": {
      "displayName": "Sumant Balli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFcJbFXv0ZDWaYwSijqTaayN_oReKkcRMbR2h21w=s64",
      "userId": "08653643334008630126"
     },
     "user_tz": -330
    },
    "id": "eRfTNJaGGa6a",
    "outputId": "d49c48ff-7f3e-4c4a-f3b9-0d053c86d7d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1445\n",
      "number of development examples = 310\n",
      "number of test examples = 310\n",
      "X_train shape: (1445, 224, 224, 3)\n",
      "Y_train shape: (1445, 1)\n",
      "X_val (dev) shape: (310, 224, 224, 3)\n",
      "Y_val (dev) shape: (310, 1)\n",
      "X_test shape: (310, 224, 224, 3)\n",
      "Y_test shape: (310, 1)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of development examples = \" + str(X_val.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_val (dev) shape: \" + str(X_val.shape))\n",
    "print (\"Y_val (dev) shape: \" + str(y_val.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_513RVy9Ga6g"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6WD5qn8OGa6k"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uV2idPJYGa6n"
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096, activation=\"relu\"))\n",
    "model.add(Dense(units=4096, activation=\"relu\"))\n",
    "model.add(Dense(units=1000, activation=\"relu\"))\n",
    "model.add(Dense(units=2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hkKkjWEWGa6q"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(lr=0.00001)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1392,
     "status": "ok",
     "timestamp": 1588151507699,
     "user": {
      "displayName": "Sumant Balli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFcJbFXv0ZDWaYwSijqTaayN_oReKkcRMbR2h21w=s64",
      "userId": "08653643334008630126"
     },
     "user_tz": -330
    },
    "id": "pDCRLM43Ga6u",
    "outputId": "2306229d-09c1-4933-ca10-f70b1c4bd480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 138,359,546\n",
      "Trainable params: 138,359,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVs_VN0lGa6z"
   },
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m}:{round(s,1)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nKBSaAZWGa62"
   },
   "outputs": [],
   "source": [
    "def compute_f1_score(y_true, prob):\n",
    "    # convert the vector of probabilities to a target vector\n",
    "    y_pred = np.where(prob > 0.5, 1, 0)\n",
    "    \n",
    "    score = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScI-z8JqGa65"
   },
   "outputs": [],
   "source": [
    "#tensorboard\n",
    "log_file_name = f'brain_tumor_detection_cnn_{int(time.time())}'\n",
    "#tensorboard = TensorBoard(log_dir=f'logs/{log_file_name}')\n",
    "early=EarlyStopping(monitor='val_accuracy',min_delta=0,patience=25,verbose=1,mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZme9oMtGa67"
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "# unique file name that will include the epoch and the validation (development) accuracy\n",
    "filepath=\"cnn-parameters-improvement-{epoch:02d}-{val_accuracy:.2f}\"\n",
    "# save the model with the best validation (development) accuracy till now\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 711984,
     "status": "ok",
     "timestamp": 1588152314882,
     "user": {
      "displayName": "Sumant Balli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFcJbFXv0ZDWaYwSijqTaayN_oReKkcRMbR2h21w=s64",
      "userId": "08653643334008630126"
     },
     "user_tz": -330
    },
    "id": "51zn6_CIGa6-",
    "outputId": "9d55f28f-10ae-44bd-ef67-8bddb4cd6e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5308WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-01-0.50.model/assets\n",
      "46/46 [==============================] - 41s 894ms/step - loss: 0.6918 - accuracy: 0.5308 - val_loss: 0.6925 - val_accuracy: 0.5032\n",
      "Epoch 2/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6909 - accuracy: 0.5308INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-02-0.50.model/assets\n",
      "46/46 [==============================] - 41s 888ms/step - loss: 0.6909 - accuracy: 0.5308 - val_loss: 0.6922 - val_accuracy: 0.5032\n",
      "Epoch 3/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6901 - accuracy: 0.5308INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-03-0.50.model/assets\n",
      "46/46 [==============================] - 41s 902ms/step - loss: 0.6901 - accuracy: 0.5308 - val_loss: 0.6924 - val_accuracy: 0.5032\n",
      "Epoch 4/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.5308INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-04-0.50.model/assets\n",
      "46/46 [==============================] - 41s 892ms/step - loss: 0.6872 - accuracy: 0.5308 - val_loss: 0.6942 - val_accuracy: 0.5032\n",
      "Epoch 5/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6873 - accuracy: 0.5308INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-05-0.50.model/assets\n",
      "46/46 [==============================] - 41s 898ms/step - loss: 0.6873 - accuracy: 0.5308 - val_loss: 0.6903 - val_accuracy: 0.5032\n",
      "Epoch 6/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6822 - accuracy: 0.5308INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-06-0.50.model/assets\n",
      "46/46 [==============================] - 39s 851ms/step - loss: 0.6822 - accuracy: 0.5308 - val_loss: 0.6933 - val_accuracy: 0.5032\n",
      "Epoch 7/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.5308INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-07-0.50.model/assets\n",
      "46/46 [==============================] - 42s 918ms/step - loss: 0.6789 - accuracy: 0.5308 - val_loss: 0.6763 - val_accuracy: 0.5032\n",
      "Epoch 8/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6178 - accuracy: 0.6304INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-08-0.62.model/assets\n",
      "46/46 [==============================] - 41s 889ms/step - loss: 0.6178 - accuracy: 0.6304 - val_loss: 0.6167 - val_accuracy: 0.6226\n",
      "Epoch 9/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4718 - accuracy: 0.7785INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-09-0.76.model/assets\n",
      "46/46 [==============================] - 41s 882ms/step - loss: 0.4718 - accuracy: 0.7785 - val_loss: 0.4747 - val_accuracy: 0.7645\n",
      "Epoch 10/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4033 - accuracy: 0.8125INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-10-0.85.model/assets\n",
      "46/46 [==============================] - 41s 892ms/step - loss: 0.4033 - accuracy: 0.8125 - val_loss: 0.4063 - val_accuracy: 0.8484\n",
      "Epoch 11/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2718 - accuracy: 0.8907INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-11-0.88.model/assets\n",
      "46/46 [==============================] - 40s 865ms/step - loss: 0.2718 - accuracy: 0.8907 - val_loss: 0.3005 - val_accuracy: 0.8839\n",
      "Epoch 12/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2052 - accuracy: 0.9253INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-12-0.85.model/assets\n",
      "46/46 [==============================] - 42s 907ms/step - loss: 0.2052 - accuracy: 0.9253 - val_loss: 0.3166 - val_accuracy: 0.8484\n",
      "Epoch 13/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1496 - accuracy: 0.9439INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-13-0.94.model/assets\n",
      "46/46 [==============================] - 40s 867ms/step - loss: 0.1496 - accuracy: 0.9439 - val_loss: 0.1657 - val_accuracy: 0.9419\n",
      "Epoch 14/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9626INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-14-0.91.model/assets\n",
      "46/46 [==============================] - 42s 906ms/step - loss: 0.0977 - accuracy: 0.9626 - val_loss: 0.2441 - val_accuracy: 0.9129\n",
      "Epoch 15/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9841INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-15-0.94.model/assets\n",
      "46/46 [==============================] - 40s 863ms/step - loss: 0.0579 - accuracy: 0.9841 - val_loss: 0.1762 - val_accuracy: 0.9355\n",
      "Epoch 16/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9869INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-16-0.96.model/assets\n",
      "46/46 [==============================] - 40s 878ms/step - loss: 0.0466 - accuracy: 0.9869 - val_loss: 0.1128 - val_accuracy: 0.9613\n",
      "Epoch 17/17\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9917INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-17-0.96.model/assets\n",
      "46/46 [==============================] - 41s 892ms/step - loss: 0.0284 - accuracy: 0.9917 - val_loss: 0.1046 - val_accuracy: 0.9581\n",
      "Elapsed time: 0:11:50.5\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=17, validation_data=(X_val, y_val), callbacks=[early, checkpoint])\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"Elapsed time: {hms_string(execution_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 83206,
     "status": "ok",
     "timestamp": 1588152451365,
     "user": {
      "displayName": "Sumant Balli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFcJbFXv0ZDWaYwSijqTaayN_oReKkcRMbR2h21w=s64",
      "userId": "08653643334008630126"
     },
     "user_tz": -330
    },
    "id": "HEWNroNWGa7C",
    "outputId": "ab25d63d-96dd-4569-e820-12b98b94321b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9972INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-01-0.97.model/assets\n",
      "46/46 [==============================] - 37s 803ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.1098 - val_accuracy: 0.9677\n",
      "Epoch 2/2\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.9716INFO:tensorflow:Assets written to: models/cnn-parameters-improvement-02-0.97.model/assets\n",
      "46/46 [==============================] - 41s 889ms/step - loss: 0.0885 - accuracy: 0.9716 - val_loss: 0.0974 - val_accuracy: 0.9742\n",
      "Elapsed time: 0:1:19.3\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=2, validation_data=(X_val, y_val), callbacks=[early, checkpoint])\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"Elapsed time: {hms_string(execution_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "epEw8dNzQW4i"
   },
   "outputs": [],
   "source": [
    "history = model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1284,
     "status": "ok",
     "timestamp": 1588152482415,
     "user": {
      "displayName": "Sumant Balli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFcJbFXv0ZDWaYwSijqTaayN_oReKkcRMbR2h21w=s64",
      "userId": "08653643334008630126"
     },
     "user_tz": -330
    },
    "id": "Dv65K-8qGa7H",
    "outputId": "5f8e0c72-9cf7-4bd7-8d8f-456ac2537d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "accuracy\n",
      "val_loss\n",
      "val_accuracy\n"
     ]
    }
   ],
   "source": [
    "for key in history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVCsjgZAGa7L"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    \n",
    "    train_loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "    train_acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "    \n",
    "    # Loss\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    \n",
    "    \n",
    "    # Accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb6e8c8a320>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vggfinal123.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
